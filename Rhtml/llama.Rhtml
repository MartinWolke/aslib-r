<!DOCTYPE html>
<html>
<head>
<title>Some LLAMA benchmark results</title>
</head>
<body>


<h2> LLAMA results </h2>

All results were produced by using the cross-validation splits in the repository with
<!--rinline getNumberOfCVFolds(astask) --> folds and <!--rinline getNumberOfCVReps(astask) --> repetitions.<br>
The best values within a type (i.e., baseline (except for vbs), classif, regr and cluster) and performance measure (i.e., Percentage solved, PAR10, MCP) are colored orange. Furthermore, the three best values over all groups within a performance measure are highlighted red.

<p>

The performance is measured in three different ways.
<ul>
<li><strong>Percentage solved</strong> records the percentage of problem
instances in the data set for which the selector selected an algorithm that was
able to solve it with runstatus "ok" and the algorithm time plus the feature
computation time was at most the timeout.</li>
<li>The <strong>penalized average runtime score (PAR10)</strong> measures the time required to
run on all problem instances. If an instance was solved within the timeout by
the algorithm the selector chose, the
actual runtime is taken. If a timeout occurred, the timeout value was multiplied
by 10.</li>
<li>The <strong>misclassification penalty (mcp)</strong> measures the additional time required to run
on all problems if sub-optimal algorithms were used. That is, if an algorithm is
run on a problem instance that is not the best, a performance loss is incurred.
There are no additional penalties or factors for timeouts. The virtual best
solver always has a misclassification penalty of zero.</li>
</ul>

<p>

<h2> Imputation by 2*Max (numeric) and extra-class (string / factor) </h2>

<p>

<!--begin.rcode, results = "asis"
  allfeats = getFeatureNames(astask)
  fsteps = config$feature.steps.default
  presolve = getCostsAndPresolvedStatus(astask)
#   if (is.null(fsteps))
#     fsteps = getFeatureStepNames(astask)
  feats = getProvidedFeatures(astask, fsteps)
  d = subset(llama.results, prob == astask$desc$task_id)
  d = refurbishLlamaResults(data = d, color.best = "#FF0000", color.best.in.group = "#FE9A2E")
  colnames(d) = c("Type", "Model", "Percentage Solved", "PAR10", "MCP")
  print(xtable(d), "html", include.rownames = FALSE, sanitize.text.function = function(x) x)
end.rcode-->

<p>

<h2> Imputation by Median </h2>

<p>

<!--begin.rcode, results = "asis"
  allfeats = getFeatureNames(astask)
  fsteps = config$feature.steps.default
  presolve = getCostsAndPresolvedStatus(astask)
#   if (is.null(fsteps))
#     fsteps = getFeatureStepNames(astask)
  feats = getProvidedFeatures(astask, fsteps)
  d = subset(llama.results2, prob == astask$desc$task_id)
  d = refurbishLlamaResults(data = d, color.best = "#FF0000", color.best.in.group = "#FE9A2E")
  colnames(d) = c("Type", "Model", "Percentage Solved", "PAR10", "MCP")
  print(xtable(d), "html", include.rownames = FALSE, sanitize.text.function = function(x) x)
end.rcode-->

<p>


The following default feature steps were used for model building:
<p>
<!--rinline collapse(fsteps, sep = ", ")  -->
<p>
Number of presolved instances: <!--rinline sum(presolve$is.presolved) -->
<p>
The cost for using the feature steps (adapted for presolving) is: <!--rinline sum(presolve$costs) --> 
or on average: <!--rinline mean(presolve$costs) -->
<p>
The feature steps correspond to the following <!--rinline length(feats)--> / <!-- rinline length(allfeats) --> features:
<p>
<!--begin.rcode, results = "asis"
  for (i in seq_along(feats)) {
    cat(feats[i]); cat(", ")
    if (i %% 5 == 0L )
      cat("<br>")
  }
end.rcode-->
<p>

</body>
</html>

