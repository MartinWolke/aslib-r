#' Convert an ASTask task object to a llama data object.
#'
#' For features, mean values are computed across repetitions.
#' For algorithms, repetitions are not supported at the moment and will result in an error.
#'
#' @param astask [\code{\link{ASTask}}]\cr
#'   Algorithm selection task.
#' @param measure [\code{character(1)}]\cr
#'   Measure to use for modeling.
#'   Default is first measure in task.
#' @param feature.steps [\code{character}]\cr
#'   Which feature steps are allowed?
#'   Default are the default feature steps or all steps
#'   in case no defaults were defined.
#' @param add.feature.costs [\code{logical(1)}]\cr
#'   If costs for features are present in runtime tasks, should they be added to the algorithm costs
#'   (because in reality you would  have to pay them)? Whether the algorithms hit the cutoff runtime
#'   is also recalculated in this case.
#'   Adding the feature costs should not be done for the
#'   baseline models, but only for proper prognostic models.
#'   If no costs are present, 0 is added as cost and a warning is issued.
#'   Default is \code{TRUE}.
#' @return Result of calling \code{\link[llama]{input}}.
#' @export
convertToLlama = function(astask, measure, feature.steps, add.feature.costs = TRUE) {
  checkArg(astask, "ASTask")
  if (missing(measure))
    measure = astask$desc$performance_measures[1]
  else
    checkArg(measure, "character", len = 1L, na.ok = FALSE)
  allsteps = names(astask$desc$feature_steps)
  if (missing(feature.steps))
    feature.steps = getDefaultFeatureStepNames(astask)
  else
    checkArg(feature.steps, subset = allsteps)
  checkArg(add.feature.costs, "logical", len = 1L, na.ok = FALSE)
  if (add.feature.costs && is.null(astask$feature.costs))
    warningf("Requested to add feature costs, but none in task. Adding always 0 feature costs.")

  desc = astask$desc
  feats = astask$feature.values
  allowed.features = getProvidedFeatures(astask, feature.steps)

  ### handle features ###

  # reduce to inst + rep + allowed features
  # note that feats is ordered by instance, then repetition
  feats = feats[, c("instance_id", "repetition", allowed.features), drop = FALSE]

  # aggregate features, only do this if repeated measurements to save time
  if (max(feats$repetition) > 1L) {
    feats = ddply(feats, c("instance_id"), function(d) {
      colMeans(d[, allowed.features, drop = FALSE])
    })
  } else {
    feats$repetition = NULL
  }
  #FIXME: maybe use a backup solver when some features are NA, instead of imputing

  # impute feature values
  # FIXME: why cant we impute without target
  # FIXME: check whether imputing the median is useful
#   cols = sapply(feats, function(x) any(is.na(x)) & (class(x) == "logical"))
#   feats = impute(feats, target = character(0), classes = list(numeric = imputeMax(2),
#     integer = imputeMax(2), character = imputeConstant("missing"),
#     factor = imputeConstant("missing"), logical = imputeMode()),
#     dummies = names(cols)[cols])$data
  cols = sapply(feats, function(x) any(is.na(x)))
  cols = names(cols)[cols]
#   cols = setNames(lapply(cols, function(x) imputeMedian()), cols)
  imputeMean = function () {
    makeImputeMethod(learn = function(data, target, col)
      mean(data[[col]], na.rm = TRUE), impute = mlr:::simpleImpute)
  }
  cols = setNames(lapply(cols, function(x) imputeMean()), cols)
  feats = impute(feats, target = character(0), cols = cols)$data

  ### handle perf values ###
  

  # note that perf + runstatus + successes is ordered by instance, then repetition
  perf = astask$algo.perf[[measure]]
  runstatus = astask$algo.runstatus
  cutoff = desc$algorithm_cutoff_time
  
  # FIXME: From here on the whole code does NOT work if we have repetitions
  # The reason is that we have not cleanly defined, what happens if on
  # one instance an algo crashes a sometimes but works otherwise 
  stopifnot(max(perf$repetition) == 1L)
  perf$repetition = runstatus$repetition = NULL
  iid = perf$instance_id
  perf$instance_id = runstatus$instance_id = NULL

  # construct successes, so far means: no NA in perf val and run status of algo is "OK"
  successes = !is.na(perf) & runstatus == "ok"
  # Note that all stuff in this object is ordered by instance_id
  presolve = getCostsAndPresolvedStatus(astask, feature.steps = feature.steps)

  # FIXME: do we have to think about min / max in the next code?
  # impute performance values and add feature costs for run time tasks
  if (desc$performance_type[measure] == "runtime" & !is.na(cutoff)) {
    impute.val = desc$algorithm_cutoff_time
    if (add.feature.costs) {
      m = ncol(perf)
      # set algorithm costs to 0 for presolved instances, they wont run
      perf[presolve$is.presolved, ] = 0
      if (is.null(astask$feature.costs))
        add = 0
      else
        add = matrix(rep(presolve$costs, m), ncol = m, byrow = FALSE)
      # add instance costs (adapated by presolving) to each alg column
      perf = perf + add
    }
    # recalculate successes wrt to new perf vals and cutoff. we spent more time due to feat costs
    successes = successes & perf <= cutoff
  } else {
    impute.val = 10 * max(perf, na.rm = TRUE)
  }
  perf[!successes] = impute.val

  # FIXME: see above
  # aggregate stochastic algorithms, only do this if repeated measurements to save time
  # if (max(perf$repetition) > 1L) {
    # perf = ddply(perf, c("instance_id", "algorithm"), function(d) {
      # colMeans(d[, measure, drop = FALSE])
    # })
  # } else {
    # perf$repetition = NULL
  # }

  # add instance_id again and then call llama
  perf = cbind(instance_id = iid, perf)
  successes = cbind(instance_id = iid, as.data.frame(successes))
  input(feats, perf, successes = successes,
    minimize = !astask$desc$maximize[[which(astask$desc$performance_measures == measure)]])
}

